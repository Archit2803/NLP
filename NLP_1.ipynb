{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP-nachwcxXR",
        "outputId": "d1597f18-f1a5-4734-8572-3a41d61fb0db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize, regexp_tokenize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"NLTK is a powerful library for natural language processing. It provides various tools for text analysis.\"\n"
      ],
      "metadata": {
        "id": "uxjMbfM8hEfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = word_tokenize(text)\n",
        "print(\"Word Tokenization:\")\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaP6i_eThpGA",
        "outputId": "d201d2b4-b75b-420d-c876-7fd7207cab37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Tokenization:\n",
            "['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'natural', 'language', 'processing', '.', 'It', 'provides', 'various', 'tools', 'for', 'text', 'analysis', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)\n",
        "print(\"\\nSentence Tokenization:\")\n",
        "print(sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJkx-eg5h7Bc",
        "outputId": "4470baae-d9b4-48b9-b814-9cc9451abff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sentence Tokenization:\n",
            "['NLTK is a powerful library for natural language processing.', 'It provides various tools for text analysis.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'\\b[A-Z][a-z]*\\b'\n",
        "regexp_tokens = regexp_tokenize(text, pattern)\n",
        "print(\"\\nRegExp Tokenization:\")\n",
        "print(regexp_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_VYQDZBh7dC",
        "outputId": "ea3f0f3e-2d58-4551-b2b2-0d6379197950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RegExp Tokenization:\n",
            "['It']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JSNNN7jzh94A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}